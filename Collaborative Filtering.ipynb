{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget -nc http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip -n ml-100k.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdTIPhjZkaQJ",
        "outputId": "8285f6ff-e11f-4383-9892-f9c981c73e65"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-03 21:24:48--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  16.8MB/s    in 0.3s    \n",
            "\n",
            "2023-12-03 21:24:48 (16.8 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n",
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "\n",
        "# I. Data Loading and Exploration\n",
        "users_columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "users = pd.read_csv('ml-100k/u.data', sep='\\t', names=users_columns)\n",
        "\n",
        "# II. Data Preprocessing\n",
        "user_data = users.pivot(index='user_id', columns='movie_id', values='rating').fillna(0)\n",
        "\n",
        "# III. Data Split\n",
        "train_data, test_data = train_test_split(users, test_size=0.2, random_state=42)\n",
        "\n",
        "# IV. User-Based Collaborative filtering\n",
        "knn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
        "knn_model.fit(user_data)\n",
        "\n",
        "# V. Evaluation\n",
        "all_movie_ids = set(users['movie_id'].unique())\n",
        "\n",
        "# including all movies\n",
        "train_user_data = train_data.pivot(index='user_id', columns='movie_id', values='rating').fillna(0).reindex(columns=all_movie_ids, fill_value=0)\n",
        "test_user_data = test_data.pivot(index='user_id', columns='movie_id', values='rating').fillna(0).reindex(columns=all_movie_ids, fill_value=0)\n",
        "\n",
        "# k-neighbors for each user in the test set\n",
        "_, indices = knn_model.kneighbors(test_user_data, n_neighbors=5)\n",
        "\n",
        "# predicted ratings\n",
        "user_predicted_ratings = np.zeros(test_user_data.shape)\n",
        "\n",
        "# Predict ratings for each user in the test set\n",
        "for i in range(len(test_user_data)):\n",
        "    neighbor_ratings = train_user_data.iloc[indices[i]].values\n",
        "    user_similarity = cosine_similarity([test_user_data.iloc[i].values], neighbor_ratings)\n",
        "    user_predicted_ratings[i] = np.dot(user_similarity, neighbor_ratings) / np.sum(np.abs(user_similarity))\n",
        "\n",
        "# VI. Evaluation Metrics\n",
        "# Flattenning arrays\n",
        "actual_ratings = test_user_data.values.flatten()\n",
        "predicted_ratings = user_predicted_ratings.flatten()\n",
        "\n",
        "# Removing zero values\n",
        "non_zero_indices = actual_ratings.nonzero()\n",
        "actual_ratings = actual_ratings[non_zero_indices]\n",
        "predicted_ratings = predicted_ratings[non_zero_indices]\n",
        "\n",
        "#RMSE\n",
        "rmse = sqrt(mean_squared_error(actual_ratings, predicted_ratings))\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "\n",
        "# Display actual vs predicted values\n",
        "results_df = pd.DataFrame({\n",
        "    'user_id': np.repeat(test_user_data.index, test_user_data.shape[1])[non_zero_indices],\n",
        "    'item_id': np.tile(test_user_data.columns, len(test_user_data))[non_zero_indices],\n",
        "    'actual_rating': actual_ratings,\n",
        "    'predicted_rating': predicted_ratings})\n",
        "\n",
        "print(results_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XC6JKuBnzbM",
        "outputId": "7eb8c7b0-8eb1-49b9-ac0e-52f1b3014310"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 2.3274645886947405\n",
            "   user_id  item_id  actual_rating  predicted_rating\n",
            "0        1        1            5.0          4.000000\n",
            "1        1        4            3.0          2.358972\n",
            "2        1        6            5.0          0.000000\n",
            "3        1        8            1.0          0.242476\n",
            "4        1       20            4.0          0.927535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RMSE which I got is relatively high and lower values are always better. However, the scale of the rating system is from 1-5 so it may only be moderately innacurate. My actual vs predicted ratings are pretty inconsistent - some show close predictions and some show predicted values that are far off from the actual values.\n",
        "Strengths: User based CF is simple and easy to implement - it leverages user preferences to make predictions. It suggests items that are liked by similar users, potentially introducing users to new and unexpected items.\n",
        "Weaknesses: The model may not be able to deal with new users or items as well without sufficient historical data. It may not provide accurate recommendations until the user or item has built up a history of interactions. Also, as the number of users and items grows, the computation of user similarity becomes more resource-intensive. For large datasets, this can impact both training and prediction times."
      ],
      "metadata": {
        "id": "1gAGCmE2vcP-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kmqgRtktnzuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, I tried implementing the same problem using the Surprise library to perform user-based collaborative filtering using the KNNBasic algorithm.\n",
        "We can see that it gives us far more accurate results as opposed to the above. This is because the Surprise library is designed specifically for building recommendation systems and provides a high-level interface for collaborative filtering and other recommendation algorithms."
      ],
      "metadata": {
        "id": "sHPrXgjN0eJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcS4rGxqmd81",
        "outputId": "a0fce11b-acd3-4be6-b8ce-5de03cb20f8b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3163755 sha256=da848a08863dcd8f046230355bf3b13846174b28cca23fb1a1f0f34147d8ed8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset, Reader, KNNBasic\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# Data Loading and Exploration\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "# Data Split\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# User-Based Collaborative filtering using Surprise\n",
        "sim_options = {'name': 'cosine', 'user_based': True}\n",
        "knn_model = KNNBasic(sim_options=sim_options)\n",
        "knn_model.fit(trainset)\n",
        "\n",
        "# Predictions\n",
        "predictions = knn_model.test(testset)\n",
        "\n",
        "# Evaluation\n",
        "rmse = accuracy.rmse(predictions)\n",
        "\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "\n",
        "# Display actual and predicted scores\n",
        "result_df = pd.DataFrame(predictions, columns=['user_id', 'item_id', 'actual_rating', 'predicted_rating', 'details'])\n",
        "result_df['actual_rating'] = result_df['actual_rating'].astype(int)\n",
        "result_df['predicted_rating'] = round(result_df['predicted_rating'], 1)\n",
        "print(result_df[['user_id', 'item_id', 'actual_rating', 'predicted_rating']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1ro7kRwmeMc",
        "outputId": "c95f21fe-c422-46bb-a562-41f393a45f61"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.0194\n",
            "Root Mean Squared Error: 1.0193536815834319\n",
            "  user_id item_id  actual_rating  predicted_rating\n",
            "0     907     143              5               4.0\n",
            "1     371     210              4               4.0\n",
            "2     218      42              4               3.9\n",
            "3     829     170              4               4.3\n",
            "4     733     277              1               3.4\n"
          ]
        }
      ]
    }
  ]
}